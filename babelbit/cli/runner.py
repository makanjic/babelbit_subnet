import gc
from typing import List, Optional, Dict
from logging import getLogger
import os
from pathlib import Path
import json
import random
import asyncio
import time

from babelbit.utils.s3_manager import S3Manager
from babelbit.utils.settings import get_settings

from babelbit.utils.predict_utterances import (
    get_current_challenge_uid, 
    predict_with_utterance_engine_multi_miner,
)
from babelbit.utils.utterance_auth import init_utterance_auth, authenticate_utterance_engine
from babelbit.utils.async_clients import close_http_clients

from babelbit.utils.miner_registry import get_miners_from_registry, Miner
from babelbit.utils.bittensor_helpers import get_subtensor, reset_subtensor
from babelbit.chute_template.schemas import BBPredictedUtterance
from babelbit.utils.file_handling import (
    get_processed_miners_for_challenge,
    save_dialogue_score_file,
    save_challenge_summary_file,
)
from babelbit.utils.challenge_status import mark_challenge_processed
from babelbit.utils.validation_submission import ValidationSubmissionClient


from babelbit.scoring.score_dialogue import score_jsonl

logger = getLogger(__name__)

s3_manager: Optional[S3Manager] = None
settings = get_settings()

def group_steps_into_utterances(utterance_steps: List[BBPredictedUtterance]) -> List[List[BBPredictedUtterance]]:
    """
    Group utterance steps into complete utterances.
    Each utterance ends when done=True (EOF token).
    """
    complete_utterances = []
    current_utterance_steps = []
    
    for step in utterance_steps:
        current_utterance_steps.append(step)
        
        # If this step marks the end of an utterance (done=True/EOF)
        if step.done:
            complete_utterances.append(current_utterance_steps.copy())
            current_utterance_steps = []
    
    # Handle any remaining steps that didn't form a complete utterance
    if current_utterance_steps:
        logger.warning(f"Found {len(current_utterance_steps)} incomplete utterance steps at end of dialogue")
        complete_utterances.append(current_utterance_steps)
    
    return complete_utterances


async def _score_miners_for_challenge(
    *,
    challenge_uid: Optional[str],
    challenge_type: str,
    miner_list: List[Miner],
    miner_dialogues: Dict[str, Dict[str, List[BBPredictedUtterance]]],
    logs_dir: Path,
    scores_dir: Path,
    submission_client: ValidationSubmissionClient,
    active_s3_manager: Optional[S3Manager],
    main_challenge_uid: Optional[str] = None,
) -> tuple[int, int, List[float]]:
    """Persist dialogue logs, score miners, and return aggregate stats."""
    total_miners_processed = 0
    total_dialogues_processed = 0
    main_challenge_uid = main_challenge_uid or challenge_uid
    all_challenge_scores: List[float] = []

    for m in miner_list:
        try:
            miner_key = m.hotkey
            miner_id = m.slug or f"uid_{m.uid}"

            dialogues = miner_dialogues.get(miner_key, {})
            if not dialogues and getattr(m, "slug", None):
                fallback_key = m.slug
                dialogues = miner_dialogues.get(fallback_key, {})
                if dialogues:
                    logger.debug("[runner] miner %s: using slug key fallback for dialogues", miner_id)
            logger.debug(
                "[runner] miner uid=%s hk=%s dialogues_count=%d",
                getattr(m, "uid", "?"),
                (m.hotkey[:16] + "..."),
                len(dialogues or {}),
            )

            if not dialogues:
                logger.warning(f"Miner {miner_id} (uid: {m.uid}, hotkey: {m.hotkey[:16]}...) has no dialogues to score")
                continue

            has_valid_predictions = False
            for dialogue_uid, utterance_steps in dialogues.items():
                for step in utterance_steps:
                    prediction = getattr(step, "prediction", "") or ""
                    if prediction.strip():
                        has_valid_predictions = True
                        break
                if has_valid_predictions:
                    break

            if not has_valid_predictions:
                logger.warning(f"Miner {miner_id} (uid: {m.uid}) has no valid predictions across {len(dialogues)} dialogues - skipping scoring")
                logger.debug("[runner] miner %s invalid/empty predictions; skipping", miner_id)
                continue

            logger.info(f"Processing {len(dialogues)} dialogues for miner {miner_id} (uid: {m.uid}, hotkey: {m.hotkey[:16]}...)")

            dialogue_scores: List[float] = []
            dialogue_uids: List[str] = []

            for dialogue_uid, utterance_steps in dialogues.items():
                dialogue_uids.append(dialogue_uid)
                logger.info(f"Miner {miner_id} produced {len(utterance_steps)} utterance steps in dialogue {dialogue_uid}")
                complete_utterances = group_steps_into_utterances(utterance_steps)
                logger.info(f"Dialogue {dialogue_uid} contains {len(complete_utterances)} complete utterances")
                events_path = logs_dir / f"dialogue_run_{challenge_uid or 'unknown'}_miner_{m.uid}__hk_{m.hotkey}__dlg_{dialogue_uid}.jsonl"
                with events_path.open("w", encoding="utf-8") as jf:
                    for utt_index, utt_steps in enumerate(complete_utterances):
                        gt = getattr(utt_steps[-1], "ground_truth", "") or ""
                        if not gt.strip():
                            logger.warning(
                                f"Skipping utterance {utt_index} in dialogue {dialogue_uid} for miner {miner_id} - "
                                f"empty ground_truth (likely timeout or early session termination)"
                            )
                            logger.debug(
                                "[runner] skipped utt_index=%d (empty GT) in dialogue=%s miner=%s",
                                utt_index,
                                dialogue_uid,
                                miner_id,
                            )
                            continue

                        for step_idx, step_obj in enumerate(utt_steps):
                            jf.write(json.dumps({
                                "event": "predicted",
                                "utterance_index": utt_index,
                                "step": step_idx,
                                "prediction": getattr(step_obj, "prediction", "") or "",
                            }) + "\n")

                        jf.write(json.dumps({
                            "event": "utterance_complete",
                            "utterance_index": utt_index,
                            "ground_truth": gt,
                        }) + "\n")
                logger.info(f"[runner] Wrote raw dialogue log: {events_path}")
                logger.debug("[runner] events_path size=%d bytes", events_path.stat().st_size if events_path.exists() else -1)

                s3_log_path = None
                if active_s3_manager:
                    s3_log_path = f"{settings.S3_LOG_DIR}/logs/{events_path.name}"
                    active_s3_manager.upload_file(str(events_path), s3_log_path)
                    logger.info(f"Uploaded raw dialogue log to S3: s3://{active_s3_manager.bucket_name}/{s3_log_path}")
                if submission_client.is_ready:
                    max_attempts = 4
                    for attempt in range(1, max_attempts + 1):
                        try:
                            ok = await submission_client.submit_validation_file(
                                file_path=events_path,
                                file_type="dialogue_run",
                                kind="dialogue_logs",
                                challenge_id=challenge_uid or "",
                                main_challenge_uid=main_challenge_uid,
                                miner_uid=getattr(m, "uid", None),
                                miner_hotkey=getattr(m, "hotkey", None),
                                dialogue_uid=dialogue_uid,
                                s3_path=s3_log_path,
                            )
                        except Exception as e:
                            ok = False
                            logger.warning("Validation submission error for %s: %s", events_path.name, e)
                        if ok:
                            break
                        if attempt < max_attempts:
                            backoff_s = min(2**attempt, 12)
                            logger.info(
                                f"Retrying validation submission for {events_path.name} "
                                f"in {backoff_s}s (attempt {attempt + 1}/{max_attempts})",
                            )
                            await asyncio.sleep(backoff_s)

                if score_jsonl is None:
                    logger.warning("score_jsonl unavailable; skipping scoring for dialogue %s", dialogue_uid)
                    continue
                try:
                    scored_doc = score_jsonl(events_path)
                    logger.debug(
                        "[runner] score_jsonl produced %d utterances for dialogue %s",
                        len(scored_doc.get("utterances", [])),
                        dialogue_uid,
                    )
                    scored_doc.update({
                        "challenge_uid": challenge_uid,
                        "challenge_type": challenge_type,
                        "miner_uid": getattr(m, "uid", None),
                        "miner_hotkey": getattr(m, "hotkey", None),
                        "dialogue_uid": dialogue_uid,
                    })
                    avg_u = float(scored_doc.get("dialogue_summary", {}).get("average_U_best_early", 0.0))
                    dialogue_scores.append(avg_u)
                    score_path = save_dialogue_score_file(scored_doc, output_dir=str(scores_dir))
                    logger.info(f"[runner] Scored dialogue {dialogue_uid} U={avg_u:.4f}")

                    s3_sub_path = None
                    if active_s3_manager:
                        s3_sub_path = f"submissions/{Path(score_path).name}"
                        active_s3_manager.upload_file(str(score_path), s3_sub_path)
                        logger.info(f"Uploaded dialogue score to S3: s3://{active_s3_manager.bucket_name}/{s3_sub_path}")
                    if submission_client.is_ready:
                        try:
                            await submission_client.submit_validation_file(
                                file_path=Path(score_path),
                                file_type="dialogue_scores",
                                kind="dialogue_scores",
                                challenge_id=challenge_uid or "",
                                main_challenge_uid=main_challenge_uid,
                                miner_uid=getattr(m, "uid", None),
                                miner_hotkey=getattr(m, "hotkey", None),
                                dialogue_uid=dialogue_uid,
                                s3_path=s3_sub_path,
                            )
                        except Exception as e:
                            logger.warning("Validation submission error for %s: %s", score_path, e)
                except Exception as e:
                    logger.warning("Failed scoring dialogue %s: %s", dialogue_uid, e)

            if dialogue_scores and dialogue_uids:
                try:
                    miner_mean_score = sum(dialogue_scores) / len(dialogue_scores)
                    summary = {
                        "challenge_uid": challenge_uid,
                        "challenge_type": challenge_type,
                        "miner_uid": getattr(m, "uid", None),
                        "miner_hotkey": getattr(m, "hotkey", None),
                        "dialogues": [
                            {"dialogue_uid": duid, "dialogue_average_u_best_early": ds, "dialogue_index": idx}
                            for idx, (duid, ds) in enumerate(zip(dialogue_uids, dialogue_scores))
                        ],
                        "challenge_mean_U": miner_mean_score,
                    }
                    summary_path = save_challenge_summary_file(summary, output_dir=str(scores_dir))
                    logger.debug(
                        "[runner] saved challenge summary for miner %s: path=%s dialogues=%d mean=%.4f",
                        miner_id,
                        str(summary_path),
                        len(dialogue_scores),
                        miner_mean_score,
                    )

                    total_miners_processed += 1
                    total_dialogues_processed += len(dialogue_scores)
                    all_challenge_scores.append(miner_mean_score)

                    s3_sub_path = None
                    if active_s3_manager:
                        s3_sub_path = f"submissions/{Path(summary_path).name}"
                        active_s3_manager.upload_file(str(summary_path), s3_sub_path)
                        logger.info(f"Uploaded challenge summary to S3: s3://{active_s3_manager.bucket_name}/{s3_sub_path}")
                    if submission_client.is_ready:
                        try:
                            await submission_client.submit_validation_file(
                                file_path=Path(summary_path),
                                file_type="challenge_scores",
                                kind="challenge_scores",
                                challenge_id=challenge_uid or "",
                                main_challenge_uid=main_challenge_uid,
                                miner_uid=getattr(m, "uid", None),
                                miner_hotkey=getattr(m, "hotkey", None),
                                dialogue_uid=None,
                                s3_path=s3_sub_path,
                            )
                        except Exception as e:
                            logger.warning("Validation submission error for %s: %s", summary_path, e)
                except Exception as e:
                    logger.warning("Failed to save challenge summary for miner %s: %s", getattr(m, "uid", "?"), e)
            else:
                logger.debug("[runner] no dialogue scores for miner %s", miner_id)

        except Exception as e:
            logger.warning(
                "Failed to process miner uid=%s slug=%s: %s",
                getattr(m, "uid", "?"),
                getattr(m, "slug", "?"),
                e,
            )
            continue

    return total_miners_processed, total_dialogues_processed, all_challenge_scores


async def runner(slug: str | None = None, utterance_engine_url: str | None = None, output_dir: Optional[str] = None, subtensor=None) -> None:
    settings = get_settings()
    NETUID = settings.BABELBIT_NETUID
    MAX_MINERS = int(os.getenv("BB_MAX_MINERS_PER_RUN", "256"))
    utterance_engine_url = utterance_engine_url or os.getenv("BB_UTTERANCE_ENGINE_URL", "http://localhost:8000")
    enable_solo_challenge = os.getenv("BB_ENABLE_SOLO_CHALLENGE", "1").lower() in {"1", "true", "yes"}
    
    # Determine directories:
    #   Raw logs:   ./logs (override with BB_OUTPUT_LOGS_DIR)
    #   Scores:     ./scores (override with BB_OUTPUT_SCORES_DIR or output_dir argument) produced after scoring
    #   output_dir argument retained for backward compatibility
    logs_dir = Path(os.getenv("BB_OUTPUT_LOGS_DIR", "logs"))
    scores_dir = Path(output_dir or os.getenv("BB_OUTPUT_SCORES_DIR", "scores"))
    logs_dir.mkdir(parents=True, exist_ok=True)
    scores_dir.mkdir(parents=True, exist_ok=True)
    logger.debug(
        "[runner] output dirs ready: logs_dir=%s scores_dir=%s (output_dir_arg=%s)",
        str(logs_dir), str(scores_dir), str(output_dir),
    )

    s3_enabled = os.getenv("BB_ENABLE_S3_UPLOADS", "0").lower() in {"1", "true", "yes"}
    global s3_manager
    if s3_enabled and s3_manager is None:
        try:
            s3_manager = S3Manager(
                bucket_name=settings.S3_BUCKET_NAME,
                access_key=settings.S3_ACCESS_KEY_ID,
                secret_key=settings.S3_SECRET_ACCESS_KEY.get_secret_value(),
                endpoint_url=settings.S3_ENDPOINT_URL or None,
                region=settings.S3_REGION,
                addressing_style=settings.S3_ADDRESSING_STYLE or "auto",
                signature_version=settings.S3_SIGNATURE_VERSION or "s3v4",
                use_ssl=settings.S3_USE_SSL,
                prefix="",  # Empty prefix so logs go directly to bucket/logs/
            )
            logger.info("S3 Manager initialized (uploads enabled)")
        except Exception as e:
            logger.warning("S3 Manager initialization failed; disabling S3 uploads: %s", e)
            s3_manager = None
    logger.debug("[runner] S3 uploads enabled=%s active=%s", s3_enabled, bool(s3_manager))

    submission_client = ValidationSubmissionClient()
    logger.debug(
        "[runner] validation submissions ready=%s endpoint=%s",
        submission_client.is_ready,
        submission_client.submit_url if submission_client else "N/A",
    )

    try:
        challenge_uid = await get_current_challenge_uid(utterance_engine_url)
    except Exception as e:
        logger.warning(f"Could not get current challenge ID: {e}")
        return
    logger.debug("[runner] fetched challenge_uid=%s from %s", challenge_uid, utterance_engine_url)

    # Prevents runner loop from running multiple times a challenge
    if challenge_uid:
        already_processed = get_processed_miners_for_challenge(str(scores_dir), challenge_uid)
        if already_processed:
            logger.info(
                f"Challenge {challenge_uid} already has {len(already_processed)} scored miners. "
                f"Skipping entire run to avoid duplicate work."
            )
            return
        else:
            logger.info(f"Challenge {challenge_uid}: No existing scores found, proceeding with miner evaluation")
            logger.debug("[runner] already_processed=%s", list(already_processed) if already_processed else [])

    try:
        miners = await get_miners_from_registry(NETUID, subtensor=subtensor)
        logger.info(f"Found {len(miners)} eligible miners from registry: {list(miners.keys())}")
        if not miners:
            logger.warning("No eligible miners found on-chain.")
            return

        miner_list = list(miners.values())
        random.shuffle(miner_list)
        miner_list = miner_list[: min(MAX_MINERS, len(miner_list))]
        logger.debug(
            "[runner] miners selected=%d (max=%d)",
            len(miner_list), MAX_MINERS,
        )

        if not miner_list:
            logger.info("No miners to process after filtering")
            return

        # Define prediction callback for all miners
        from babelbit.utils.predict_engine import call_miner_model_on_chutes, call_miner_axon_endpoint
        
        # Capture timeout value from settings before defining callback
        chutes_timeout = settings.CHUTES_TIMEOUT_SEC
        
        async def prediction_callback(miner: Miner, payload: BBPredictedUtterance, context: str) -> str:
            """
            Callback to get prediction from a single miner.
            Returns the prediction text or empty string on error.
            Exceptions are raised to be handled by the multi-miner function.
            """
            if miner.slug:
                try:
                    # Call via Chutes
                    result = await call_miner_model_on_chutes(
                        slug=miner.slug,
                        payload=payload,
                        context_used=context,
                        timeout=chutes_timeout
                    )
                    
                    if result.success and result.utterance:
                        return result.utterance.prediction
                    else:
                        # Raise exception so the multi-miner function can handle error tracking
                        raise RuntimeError(f"{result.error}")
                except Exception as e:
                    logger.warning(f"Miner {miner.uid} chute error: {e}, trying axon fallback")
            if miner.axon_ip and miner.axon_port:
                try:
                    # Call via Axon endpoint with Bittensor protocol
                    result = await call_miner_axon_endpoint(
                        axon_ip=miner.axon_ip,
                        axon_port=miner.axon_port,
                        payload=payload,
                        context_used=context,
                        miner_hotkey=miner.hotkey,
                        timeout=chutes_timeout
                    )
                    
                    if result.success and result.utterance:
                        return result.utterance.prediction
                    else:
                        raise RuntimeError(f"{result.error}")
                except Exception as e:
                    logger.error(f"Miner {miner.uid} axon error: {e}")
                    raise
            # Neither chute nor axon available
            raise RuntimeError(f"Miner {miner.uid} has neither chute slug nor axon endpoint available")
        
        logger.info(f"Starting shared utterance session for {len(miner_list)} miners")
        
        # Get step block modulo from environment (default: 1 block)
        step_block_modulo = int(os.getenv("BB_STEP_BLOCK_MODULO", "0"))
        logger.debug(
            "[runner] session params: timeout=%.2fs step_block_modulo=%d", chutes_timeout, step_block_modulo
        )
        
        miner_dialogues = await predict_with_utterance_engine_multi_miner(
            utterance_engine_url=utterance_engine_url,
            miners=miner_list,
            prediction_callback=prediction_callback,
            timeout=chutes_timeout,
            max_prediction_errors=5,
            subtensor=subtensor,
            step_block_modulo=step_block_modulo
        )
        try:
            miners_with_dialogues = len(miner_dialogues or {})
            total_dialogues = sum(len(v) for v in (miner_dialogues or {}).values())
            logger.debug(
                "[runner] multi-miner collected: miners_with_dialogues=%d total_dialogues=%d",
                miners_with_dialogues, total_dialogues,
            )
        except Exception:
            pass
        
        total_miners_processed, total_dialogues_processed, all_challenge_scores = await _score_miners_for_challenge(
            challenge_uid=challenge_uid,
            challenge_type="main",
            miner_list=miner_list,
            miner_dialogues=miner_dialogues or {},
            logs_dir=logs_dir,
            scores_dir=scores_dir,
            submission_client=submission_client,
            active_s3_manager=s3_manager,
        )

        if enable_solo_challenge:
            try:
                solo_dialogues, solo_uid, solo_status = await predict_with_utterance_engine_multi_miner(
                    utterance_engine_url=utterance_engine_url,
                    miners=miner_list,
                    prediction_callback=prediction_callback,
                    timeout=chutes_timeout,
                    max_prediction_errors=5,
                    subtensor=None,
                    step_block_modulo=0,
                    solo=True,
                    miner_key_fn=lambda miner: getattr(miner, "hotkey", None)
                    or getattr(miner, "slug", None)
                    or f"uid_{getattr(miner, 'uid', '?')}",
                    return_challenge_uid=True,
                    return_miner_status=True,
                )
                solo_results = {
                    miner_key: {"challenge_uid": solo_uid, "dialogues": dialogues}
                    for miner_key, dialogues in (solo_dialogues or {}).items()
                    if solo_status.get(miner_key, True)
                }
            except Exception as e:
                logger.warning("[Solo Challenge] Failed to run solo challenge: %s", e)
                solo_results = {}

            if solo_results:
                solo_total_miners = 0
                solo_total_dialogues = 0

                for miner in miner_list:
                    miner_key = getattr(miner, "hotkey", None) or getattr(miner, "slug", None)
                    if not miner_key or miner_key not in solo_results:
                        continue
                    result = solo_results[miner_key]
                    solo_uid = result.get("challenge_uid")
                    miner_dialogues = result.get("dialogues") or {}

                    if not solo_uid:
                        logger.warning("[Solo Challenge] Miner %s returned no challenge UID; skipping scoring", miner_key)
                        continue

                    m_processed, d_processed, m_scores = await _score_miners_for_challenge(
                        challenge_uid=solo_uid,
                        challenge_type="solo",
                        miner_list=[miner],
                        miner_dialogues={miner_key: miner_dialogues},
                        logs_dir=logs_dir,
                        scores_dir=scores_dir,
                        submission_client=submission_client,
                        active_s3_manager=s3_manager,
                        main_challenge_uid=challenge_uid,
                    )

                    solo_total_miners += m_processed
                    solo_total_dialogues += d_processed

                    if m_processed > 0:
                        solo_mean = sum(m_scores) / len(m_scores) if m_scores else None
                        mark_challenge_processed(
                            challenge_uid=solo_uid,
                            miner_count=m_processed,
                            total_dialogues=d_processed,
                            mean_score=solo_mean,
                            metadata={
                                "scores_dir": str(scores_dir),
                                "logs_dir": str(logs_dir),
                                "solo_challenge": True,
                                "paired_challenge_uid": challenge_uid,
                            },
                        )
                        solo_mean_str = f"{solo_mean:.4f}" if solo_mean is not None else "N/A"
                        logger.info(
                            f"[Solo Challenge] Completed {solo_uid}: {m_processed} miners, "
                            f"{d_processed} dialogues, mean_score={solo_mean_str}"
                        )
                if solo_total_miners == 0:
                    logger.info("[Solo Challenge] No miners processed during solo phase")
            else:
                logger.info("[Solo Challenge] No solo challenge results returned; skipping solo scoring")
        else:
            logger.debug("[runner] Solo challenge phase disabled via BB_ENABLE_SOLO_CHALLENGE")

        if challenge_uid and total_miners_processed > 0:
            overall_mean = sum(all_challenge_scores) / len(all_challenge_scores) if all_challenge_scores else None
            mark_challenge_processed(
                challenge_uid=challenge_uid,
                miner_count=total_miners_processed,
                total_dialogues=total_dialogues_processed,
                mean_score=overall_mean,
                metadata={
                    "scores_dir": str(scores_dir),
                    "logs_dir": str(logs_dir),
                }
            )
            logger.debug(
                "[runner] challenge processed: uid=%s miners=%d dialogues=%d mean=%s",
                challenge_uid, total_miners_processed, total_dialogues_processed,
                (f"{overall_mean:.4f}" if overall_mean is not None else "N/A"),
            )
            mean_score_str = f"{overall_mean:.4f}" if overall_mean is not None else "N/A"
            logger.info(
                f"Challenge {challenge_uid} completed: {total_miners_processed} miners, "
                f"{total_dialogues_processed} dialogues, mean_score={mean_score_str}"
            )
                
    except Exception as e:
        logger.error(f"Runner failed: {type(e).__name__}: {e}", exc_info=True)
    finally:
        close_http_clients()


async def runner_loop():
    """Runs `runner()` every N blocks (default: 2160)."""
    settings = get_settings()
    TEMPO = int(os.getenv("BABELBIT_RUNNER_TEMPO", "2160"))
    MAX_SUBTENSOR_RETRIES = int(os.getenv("BABELBIT_MAX_SUBTENSOR_RETRIES", "5"))

    st = None
    last_block = -1
    last_successful_run = 0
    consecutive_failures = 0
    run_count = 0
    
    # Initialize utterance engine authentication on startup
    utterance_engine_url = os.getenv("BB_UTTERANCE_ENGINE_URL", "https://api.babelbit.ai")
    wallet_name = os.getenv("BITTENSOR_WALLET_COLD", "default")
    hotkey_name = os.getenv("BITTENSOR_WALLET_HOT", "default")
    
    init_utterance_auth(utterance_engine_url, wallet_name, hotkey_name)
    
    # Authenticate with retry logic on startup
    try:
        logger.info("[RunnerLoop] Authenticating with utterance engine on startup...")
        await authenticate_utterance_engine()
        logger.info("[RunnerLoop] Successfully authenticated with utterance engine")
    except Exception as e:
        logger.error(f"[RunnerLoop] Failed to authenticate with utterance engine on startup: {e}")
        logger.error("[RunnerLoop] Cannot proceed without authentication. Exiting.")
        return

    try:
        while True:
            try:
                if st is None:
                    logger.info(f"[RunnerLoop] Attempting to connect to subtensor (attempt {consecutive_failures + 1}/{MAX_SUBTENSOR_RETRIES})...")
                    try:
                        await reset_subtensor()  # Clear any stale cached connection
                        st = await asyncio.wait_for(get_subtensor(), timeout=60)
                        logger.info("[RunnerLoop] Successfully created subtensor connection")
                        
                        # Test the connection by fetching a block
                        test_block = await asyncio.wait_for(st.get_current_block(), timeout=30)
                        logger.info(f"[RunnerLoop] Connection verified at block {test_block}")
                        
                    except asyncio.TimeoutError as te:
                        st = None  # Clear invalid connection
                        await reset_subtensor()  # Also clear the global cache
                        raise TimeoutError(f"Subtensor initialization timed out: {te}")
                    except Exception as e:
                        st = None  # Clear invalid connection
                        await reset_subtensor()  # Also clear the global cache
                        logger.error(f"[RunnerLoop] Subtensor connection failed: {type(e).__name__}: {e}", exc_info=True)
                        raise

                # Try to get current block for tempo-based scheduling
                should_run = False
                block = None
                use_time_fallback = False
                
                try:
                    block = await asyncio.wait_for(st.get_current_block(), timeout=30)
                    logger.debug(f"[RunnerLoop] Current block: {block}")

                    # Refresh authentication 100 blocks before each run (or less if TEMPO < 100)
                    auth_refresh_offset = TEMPO - min(100, max(1, TEMPO - 1))
                    if block % TEMPO == auth_refresh_offset:
                        try:
                            logger.info(f"[RunnerLoop] Refreshing authentication at block {block} ({TEMPO - auth_refresh_offset} blocks before next run)")
                            await authenticate_utterance_engine()
                            logger.info("[RunnerLoop] Authentication refresh successful")
                        except Exception as auth_e:
                            logger.error(f"[RunnerLoop] Authentication refresh failed: {auth_e}")
                            # Don't stop the loop, but this will cause issues for the next runner() call
                    
                    # run immediately on startup if configured
                    if (settings.BB_RUNNER_ON_STARTUP and last_successful_run == 0) or (block > last_block and block % TEMPO == 0):
                        should_run = True
                        logger.info(f"[RunnerLoop] Triggering runner at block {block}")
                    else:
                        # Wait for next block with timeout
                        try:
                            await asyncio.wait_for(st.wait_for_block(), timeout=60)
                        except asyncio.TimeoutError:
                            # Don't reset on timeout - just log and retry
                            logger.debug("[RunnerLoop] wait_for_block timeout (60s) â€” retrying")
                            await asyncio.sleep(5)
                        except Exception as e:
                            logger.warning(f"[RunnerLoop] wait_for_block error: {e}")
                            st = None
                            await reset_subtensor()
                        continue
                        
                except Exception as e:
                    # Block fetch failed - fall back to time-based scheduling
                    logger.warning(f"[RunnerLoop] Block fetch failed: {type(e).__name__}: {e}")
                    st = None  # Force reconnection on next iteration
                    await reset_subtensor()  # Clear the global cached connection
                    
                    time_elapsed = time.time() - last_successful_run
                    expected_interval = TEMPO * 12  # TEMPO blocks * ~12 seconds per block
                    
                    if last_successful_run > 0 and time_elapsed >= expected_interval:
                        should_run = True
                        use_time_fallback = True
                        logger.warning(
                            f"[RunnerLoop] Blockchain unreachable. Using time-based fallback: "
                            f"elapsed={time_elapsed:.0f}s, expected={expected_interval:.0f}s"
                        )
                    else:
                        # Not enough time has passed, or first run - skip and let retry logic handle it
                        if last_successful_run == 0:
                            logger.info("[RunnerLoop] First run - will retry connection")
                        else:
                            logger.info(f"[RunnerLoop] Only {time_elapsed:.0f}s elapsed (need {expected_interval:.0f}s), will retry")
                        raise  # Re-raise to trigger retry logic
                        
                if should_run:
                    if use_time_fallback:
                        logger.info("[RunnerLoop] Running validation via time-based fallback (blockchain unreachable)")
                    
                    await runner(subtensor=st if st is not None else None)
                    
                    if block is not None:
                        last_block = block
                    last_successful_run = time.time()
                    consecutive_failures = 0  # Reset after successful validation cycle
                    run_count += 1
                    logger.info(f"[RunnerLoop] Completed runner cycle #{run_count}")
                    
                    if run_count >= 10:
                        logger.info("[RunnerLoop] Reached 10 successful runs, resetting subtensor connection to free resources.")
                        st = None
                        await reset_subtensor()
                        run_count = 0
                        gc.collect()

            except asyncio.CancelledError:
                break
            except Exception as e:
                consecutive_failures += 1
                logger.warning(
                    f"[RunnerLoop] Error (attempt {consecutive_failures}/{MAX_SUBTENSOR_RETRIES}): {type(e).__name__}: {e}"
                )
                
                if consecutive_failures >= MAX_SUBTENSOR_RETRIES:
                    logger.error(
                        f"[RunnerLoop] Max retries ({MAX_SUBTENSOR_RETRIES}) exceeded. "
                        f"Endpoints: primary={settings.BITTENSOR_SUBTENSOR_ENDPOINT}, "
                        f"fallback={settings.BITTENSOR_SUBTENSOR_FALLBACK}"
                    )
                    logger.error(
                        "[RunnerLoop] Unable to connect to Bittensor network. "
                        "Sleeping for 5 minutes before retry cycle..."
                    )
                    consecutive_failures = 0  # Reset counter
                    st = None
                    await asyncio.sleep(300)  # Sleep 5 minutes before trying again
                else:
                    logger.info(f"[RunnerLoop] Retrying in 120 seconds...")
                    st = None
                    await asyncio.sleep(120)
    finally:
        # Ensure cleanup on exit
        logger.info("[RunnerLoop] Shutting down, cleaning up resources...")
        close_http_clients()
